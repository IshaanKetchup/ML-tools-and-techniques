{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMlL1Ex6QXs2SWs9Lc1oZXg",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "a649a4ee6a264bb0b206616ae4407009": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1eb6aa4db6e7440e9b19643caa991f34",
              "IPY_MODEL_807b9d2a569e431aa7b08a0c41ed4a95",
              "IPY_MODEL_d29ba34dd5b14fb1aabda4c6384d75b3"
            ],
            "layout": "IPY_MODEL_2da7669f27d044c096d3121648794f64"
          }
        },
        "1eb6aa4db6e7440e9b19643caa991f34": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_aeb25ce111cb4997a7dc107272cef95d",
            "placeholder": "​",
            "style": "IPY_MODEL_4b1426f3d60a49708d0819c70ca499e1",
            "value": "config.json: 100%"
          }
        },
        "807b9d2a569e431aa7b08a0c41ed4a95": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8595b41c4db84ebda491b024ce23448d",
            "max": 570,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_96949d7916484445b5a923d2069eb18d",
            "value": 570
          }
        },
        "d29ba34dd5b14fb1aabda4c6384d75b3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8c8f0c2805404bd589fe82c744ef9c36",
            "placeholder": "​",
            "style": "IPY_MODEL_b09682d5db15461d819737f705be3c61",
            "value": " 570/570 [00:00&lt;00:00, 43.1kB/s]"
          }
        },
        "2da7669f27d044c096d3121648794f64": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "aeb25ce111cb4997a7dc107272cef95d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4b1426f3d60a49708d0819c70ca499e1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8595b41c4db84ebda491b024ce23448d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "96949d7916484445b5a923d2069eb18d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8c8f0c2805404bd589fe82c744ef9c36": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b09682d5db15461d819737f705be3c61": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b9cdc07eb2bd4767b3b7e5037a3ce97f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_db59b2af29f74e0ea04ba75fbd59ac05",
              "IPY_MODEL_91c1eec18c3b470994edfc24cd960acb",
              "IPY_MODEL_e03346de612848c2bea160b047421238"
            ],
            "layout": "IPY_MODEL_9f90d04920594790a5cbe46a7d7fec30"
          }
        },
        "db59b2af29f74e0ea04ba75fbd59ac05": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4e1494709cc847208e1857b20dd05d44",
            "placeholder": "​",
            "style": "IPY_MODEL_6996f3247c8d4041b9b289a46e1f590b",
            "value": "model.safetensors: 100%"
          }
        },
        "91c1eec18c3b470994edfc24cd960acb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a8e02edc6be84489ae93b623f369f9cf",
            "max": 440449768,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_851d43a90c634edfb153cab961c3fa7d",
            "value": 440449768
          }
        },
        "e03346de612848c2bea160b047421238": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_12d190a2146049a78b8410d9f574739d",
            "placeholder": "​",
            "style": "IPY_MODEL_df45ae74daa944e3bbf8d1d719c9658a",
            "value": " 440M/440M [00:10&lt;00:00, 44.2MB/s]"
          }
        },
        "9f90d04920594790a5cbe46a7d7fec30": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4e1494709cc847208e1857b20dd05d44": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6996f3247c8d4041b9b289a46e1f590b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a8e02edc6be84489ae93b623f369f9cf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "851d43a90c634edfb153cab961c3fa7d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "12d190a2146049a78b8410d9f574739d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "df45ae74daa944e3bbf8d1d719c9658a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/IshaanKetchup/ML-tools-and-techniques/blob/main/Fine%20Tuning%20LLMs.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##PEFT - Parameter Efficient Fine Tuning"
      ],
      "metadata": {
        "id": "0DhS3V895oqw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Choosing which layers to fine tune"
      ],
      "metadata": {
        "id": "Pzzo8j_T535z"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 246,
          "referenced_widgets": [
            "a649a4ee6a264bb0b206616ae4407009",
            "1eb6aa4db6e7440e9b19643caa991f34",
            "807b9d2a569e431aa7b08a0c41ed4a95",
            "d29ba34dd5b14fb1aabda4c6384d75b3",
            "2da7669f27d044c096d3121648794f64",
            "aeb25ce111cb4997a7dc107272cef95d",
            "4b1426f3d60a49708d0819c70ca499e1",
            "8595b41c4db84ebda491b024ce23448d",
            "96949d7916484445b5a923d2069eb18d",
            "8c8f0c2805404bd589fe82c744ef9c36",
            "b09682d5db15461d819737f705be3c61",
            "b9cdc07eb2bd4767b3b7e5037a3ce97f",
            "db59b2af29f74e0ea04ba75fbd59ac05",
            "91c1eec18c3b470994edfc24cd960acb",
            "e03346de612848c2bea160b047421238",
            "9f90d04920594790a5cbe46a7d7fec30",
            "4e1494709cc847208e1857b20dd05d44",
            "6996f3247c8d4041b9b289a46e1f590b",
            "a8e02edc6be84489ae93b623f369f9cf",
            "851d43a90c634edfb153cab961c3fa7d",
            "12d190a2146049a78b8410d9f574739d",
            "df45ae74daa944e3bbf8d1d719c9658a"
          ]
        },
        "id": "kKH2VoFY5l9u",
        "outputId": "264785a8-bfef-4783-c2cb-83b5a353edf1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a649a4ee6a264bb0b206616ae4407009"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b9cdc07eb2bd4767b3b7e5037a3ce97f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ],
      "source": [
        "# Load pre-trained BERT model\n",
        "from transformers import BertForSequenceClassification\n",
        "\n",
        "model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=3)\n",
        "\n",
        "# Step 1: Freeze all layers except the last one (classification head)\n",
        "for param in model.base_model.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "# If you'd like to fine-tune additional layers (e.g., the last 2 layers), you can unfreeze those layers as well\n",
        "for param in model.base_model.encoder.layer[-2:].parameters():\n",
        "    param.requires_grad = True"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Set-up fine tuning with PEFT\n",
        "\n",
        "Hugging Face provides pretrained models like BERT that are used in this example.\n",
        "\n",
        "We use their Trainer and TrainingArguments classes to handle the fine-tuning process, which allows us to specify parameters such as the number of epochs, batch size, and datasets to use."
      ],
      "metadata": {
        "id": "JGjtU9Uz6DEs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Instructions for fine-tuning with PEFT\n",
        "1. Freeze the layers of the model (as shown in the previous code block).\n",
        "2. Set up the fine-tuning process using Hugging Face’s Trainer class and TrainingArguments, continuing from Step 1.\n",
        "3. Fine-tune the model based on the trainer setup, which is also shown in this code block."
      ],
      "metadata": {
        "id": "zzWfS29j6Lz8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import Trainer, TrainingArguments\n",
        "\n",
        "# Step 1: Set training arguments for fine-tuning the model\n",
        "training_args = TrainingArguments(\n",
        "    output_dir='./results',             # Directory where results will be stored\n",
        "    num_train_epochs=3,                 # Number of epochs (full passes through the dataset)\n",
        "    per_device_train_batch_size=16,     # Batch size per GPU/CPU during training\n",
        "    eval_strategy=\"epoch\",        # Evaluate the model at the end of each epoch\n",
        ")\n",
        "\n",
        "# Step 2: Fine-tune only the final classification head (since earlier layers were frozen)\n",
        "trainer = Trainer(\n",
        "    model=model,                        # Pre-trained BERT model with frozen layers\n",
        "    args=training_args,                 # Training arguments\n",
        "    train_dataset=train_data,           # Training data for fine-tuning\n",
        "    eval_dataset=val_data,              # Validation data to evaluate performance during training\n",
        ")\n",
        "\n",
        "# Step 3: Train the model using PEFT (this performs PEFT because layers were frozen in Step 1)\n",
        "trainer.train()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 219
        },
        "id": "Id6C18136E7g",
        "outputId": "cdd8fa1a-94e9-4cc0-9de6-ecc2661e9397"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'train_data' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3-288574265.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m                        \u001b[0;31m# Pre-trained BERT model with frozen layers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining_args\u001b[0m\u001b[0;34m,\u001b[0m                 \u001b[0;31m# Training arguments\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m     \u001b[0mtrain_dataset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m,\u001b[0m           \u001b[0;31m# Training data for fine-tuning\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m     \u001b[0meval_dataset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_data\u001b[0m\u001b[0;34m,\u001b[0m              \u001b[0;31m# Validation data to evaluate performance during training\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m )\n",
            "\u001b[0;31mNameError\u001b[0m: name 'train_data' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Monitor and Evaluate Performance"
      ],
      "metadata": {
        "id": "NaEtis_H6dgm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model\n",
        "results = trainer.evaluate(eval_dataset=test_data)\n",
        "print(f\"Test Accuracy: {results['eval_accuracy']}\")"
      ],
      "metadata": {
        "id": "DoUQJztR6Sis"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Optimize PEFT for your task"
      ],
      "metadata": {
        "id": "fiv7gxxA6keu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Example of adjusting learning rate for PEFT optimization\n",
        "training_args = TrainingArguments(\n",
        "    output_dir='./results',\n",
        "    learning_rate=5e-5,  # Experiment with different learning rates\n",
        "    num_train_epochs=5,\n",
        "    per_device_train_batch_size=16,\n",
        ")"
      ],
      "metadata": {
        "id": "rYT81xPI6lhe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Low Rank Adaptation LoRA\n",
        "Traditional fine-tuning methods require adjusting all the parameters in a model, which is resource-intensive, especially for large transformer-based models like BERT, RoBERTa, and GPT. As models grow larger, the computational and memory costs of full fine-tuning increase substantially. LoRA addresses these challenges by applying low-rank adaptations within specific layers, focusing on fine-tuning only a subset of parameters that represent a low-rank approximation of the original model's weight matrices.\n",
        "\n",
        "The benefits of LoRA:\n",
        "* Reduced Memory Usage\n",
        "* Lower Computational Cost\n",
        "* Faster Training and Experimentation"
      ],
      "metadata": {
        "id": "GRS_Snw28ASV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Explanation:\n",
        "* print(name): prints each model component to help locate the attention layers where LoRA can be applied.\n",
        "* module.apply(LoRALayer): applies the LoRA modification to the identified attention layers.\n",
        "* param.requires_grad = False: ensures all other parameters remain frozen, meaning only LoRA-modified layers will be fine-tuned."
      ],
      "metadata": {
        "id": "i6RYkcQN8kyp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from lora import LoRALayer\n",
        "from transformers import BertForSequenceClassification\n",
        "\n",
        "# Load a pre-trained BERT model for classification tasks\n",
        "model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=3)\n",
        "\n",
        "# Print model layers to identify attention layers where LoRA can be applied\n",
        "for name, module in model.named_modules():\n",
        "    print(name)  # This output helps locate attention layers\n",
        "\n",
        "# Apply LoRA to attention layers\n",
        "for name, module in model.named_modules():\n",
        "    if 'attention' in name:\n",
        "        module.apply(LoRALayer)\n",
        "\n",
        "# Freeze other layers to update only LoRA-modified parameters\n",
        "for param in model.base_model.parameters():\n",
        "    param.requires_grad = False"
      ],
      "metadata": {
        "id": "wCw84dSw8B5E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Fine tune with LoRA"
      ],
      "metadata": {
        "id": "RiYYKAIK8kYy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import Trainer, TrainingArguments\n",
        "\n",
        "# Configure training parameters\n",
        "training_args = TrainingArguments(\n",
        "    output_dir='./results',\n",
        "    num_train_epochs=3,\n",
        "    per_device_train_batch_size=16,\n",
        "    evaluation_strategy=\"epoch\",\n",
        ")\n",
        "\n",
        "# Set up the Trainer to handle fine-tuning\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_data,\n",
        "    eval_dataset=val_data,\n",
        ")\n",
        "\n",
        "# Begin training\n",
        "trainer.train()"
      ],
      "metadata": {
        "id": "rzd1zpT28t12"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Evaluate"
      ],
      "metadata": {
        "id": "-Jxgo7yZ8v-v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the LoRA fine-tuned model on the test set\n",
        "results = trainer.evaluate(eval_dataset=test_data)\n",
        "print(f\"Test Accuracy: {results['eval_accuracy']}\")"
      ],
      "metadata": {
        "id": "rZnhlITW8wrB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Optimize LoRA"
      ],
      "metadata": {
        "id": "cvDUdfBF8yDP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Example of adjusting the rank in LoRA\n",
        "from lora import adjust_lora_rank\n",
        "\n",
        "# Set a lower rank for fine-tuning, experiment with values for optimal performance\n",
        "adjust_lora_rank(model, rank=2)"
      ],
      "metadata": {
        "id": "P8DbxxdC8zAs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Quantized LoRA\n",
        "QLoRA enhances the fine-tuning process by applying quantization, which reduces the precision of the model's weights (e.g., from 32-bit to 8-bit or even 4-bit), lowering the memory and computational requirements. Quantizing a model involves approximating the model's weight values to lower-precision numbers, significantly reducing the memory footprint while preserving much of the model's performance. This makes fine-tuning feasible on smaller hardware such as consumer graphics processing units (GPUs)."
      ],
      "metadata": {
        "id": "eKFUmW24-3lw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this example, the pretrained GPT-2 model is quantized to 8 bits, drastically reducing its memory requirements. LoRA is then applied to specific layers, such as attention heads, to ensure that only a small subset of parameters is fine-tuned."
      ],
      "metadata": {
        "id": "7wlBpcvZ-8IR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import GPT2ForSequenceClassification\n",
        "from qlora import QuantizeModel, LoRALayer\n",
        "\n",
        "# Load the pre-trained GPT-2 model\n",
        "model = GPT2ForSequenceClassification.from_pretrained('gpt2')\n",
        "\n",
        "# Quantize the model\n",
        "quantized_model = QuantizeModel(model, bits=8)\n",
        "\n",
        "# Apply LoRA to specific layers (e.g., attention layers)\n",
        "for name, module in quantized_model.named_modules():\n",
        "    if 'attention' in name:\n",
        "        module.apply(LoRALayer)"
      ],
      "metadata": {
        "id": "61lPtSRJ-487"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import Trainer, TrainingArguments\n",
        "\n",
        "# Set up training arguments\n",
        "training_args = TrainingArguments(\n",
        "    output_dir='./results',\n",
        "    num_train_epochs=3,\n",
        "    per_device_train_batch_size=16,\n",
        "    evaluation_strategy=\"epoch\",\n",
        ")\n",
        "\n",
        "# Fine-tune the QLoRA-enhanced model\n",
        "trainer = Trainer(\n",
        "    model=quantized_model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_data,\n",
        "    eval_dataset=val_data,\n",
        ")\n",
        "\n",
        "# Train the model\n",
        "trainer.train()"
      ],
      "metadata": {
        "id": "oyAdZWZm_DsL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model on the test set\n",
        "results = trainer.evaluate(eval_dataset=test_data)\n",
        "print(f\"Test Accuracy: {results['eval_accuracy']}\")"
      ],
      "metadata": {
        "id": "8JI-Xg-R_GNq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from qlora import adjust_qlora_rank\n",
        "\n",
        "# Adjust the rank of the low-rank matrices\n",
        "adjust_qlora_rank(quantized_model, rank=4)  # Experiment with different rank values"
      ],
      "metadata": {
        "id": "-oJhbIJk_Hbx"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}