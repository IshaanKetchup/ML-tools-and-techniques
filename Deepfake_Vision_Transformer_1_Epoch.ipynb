{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/IshaanKetchup/ML-tools-and-techniques/blob/main/Deepfake_Vision_Transformer_1_Epoch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6fJjBnVCSKpp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "368ed073-4f55-43fd-b2b6-0ba5a5d6a6df",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: timm in /usr/local/lib/python3.11/dist-packages (1.0.16)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (from timm) (2.6.0+cu124)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (from timm) (0.21.0+cu124)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from timm) (6.0.2)\n",
            "Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.11/dist-packages (from timm) (0.33.1)\n",
            "Requirement already satisfied: safetensors in /usr/local/lib/python3.11/dist-packages (from timm) (0.5.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface_hub->timm) (3.18.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub->timm) (2025.3.2)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub->timm) (24.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface_hub->timm) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub->timm) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub->timm) (4.14.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub->timm) (1.1.5)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch->timm) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch->timm) (3.1.6)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch->timm)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch->timm)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch->timm)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch->timm)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch->timm)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch->timm)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch->timm)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch->timm)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch->timm)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch->timm) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch->timm) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->timm) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch->timm)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch->timm) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch->timm) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch->timm) (1.3.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchvision->timm) (2.0.2)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision->timm) (11.2.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch->timm) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub->timm) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub->timm) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub->timm) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub->timm) (2025.6.15)\n",
            "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m57.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m33.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m47.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m11.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m57.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127\n"
          ]
        }
      ],
      "source": [
        "pip install timm\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KyxYjCUtKyvj",
        "outputId": "2ff00d9b-f195-4cc1-db98-f2a2620add2b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Path to dataset files: /root/.cache/kagglehub/datasets/manjilkarki/deepfake-and-real-images/versions/1\n"
          ]
        }
      ],
      "source": [
        "import kagglehub\n",
        "import os\n",
        "# Download dataset\n",
        "path = kagglehub.dataset_download(\"manjilkarki/deepfake-and-real-images\")\n",
        "print(\"Path to dataset files:\", path)\n",
        "\n",
        "dataset_path = \"/root/.cache/kagglehub/datasets/manjilkarki/deepfake-and-real-images/versions/1/Dataset\"\n",
        "train_dir = os.path.join(dataset_path, \"Train\")\n",
        "val_dir = os.path.join(dataset_path, \"Validation\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "from torch import nn\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader\n",
        "import timm\n",
        "\n",
        "# Device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4don7EtxjdCF",
        "outputId": "3b536c49-b534-4c4a-812e-8d780d03bb01"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Transforms\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.5]*3, [0.5]*3)\n",
        "])\n",
        "\n",
        "# Datasets and loaders\n",
        "train_dataset = datasets.ImageFolder(train_dir, transform=transform)\n",
        "val_dataset = datasets.ImageFolder(val_dir, transform=transform)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=2)\n",
        "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False, num_workers=2)"
      ],
      "metadata": {
        "id": "P3iD8_VCjfts"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "\n",
        "# Model: Vision Transformer\n",
        "model = timm.create_model('vit_base_patch16_224', pretrained=True, num_classes=2)\n",
        "model = model.to(device)\n",
        "\n",
        "# Loss & Optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=3e-4)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "CcJ1n0LyaI88",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 178,
          "referenced_widgets": [
            "2ac6d8d7fc84440fb3e065636e809bd1",
            "ea29a63974f74243ae044d5fae83f6ea",
            "8dd51d8914c642108776d3a4d90b3193",
            "40e3e375d3a54cf39fecca4c65ec0cb8",
            "d6de4cf463aa46f5b02bce94dea6a97e",
            "41b21d0595024a5cbaffef83abd179e7",
            "c0dfff3c06a04ad9a9251bc32057ac9f",
            "4cc67ea2a56b46e9bc9a12d2aa0bb5ec",
            "289a43eec8cb43929c4ee3610f2f8b81",
            "cb9c347670d84cb18f7087629918e67e",
            "deed8aa958c148f9bbe33b789f3bda56"
          ]
        },
        "outputId": "be652d4e-db67-4baf-80a6-82a045c1c54d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/346M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2ac6d8d7fc84440fb3e065636e809bd1"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"GPU available:\", torch.cuda.is_available())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EofxNLnQycwv",
        "outputId": "dac4afff-a096-4d66-deb3-9ce8cb7f09a9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU available: True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "\n",
        "start = time.time()\n",
        "for i, (images, labels) in enumerate(train_loader):\n",
        "    print(f\"Batch {i+1}: {images.shape}, {labels.shape}\")\n",
        "    if i == 2: break\n",
        "print(\"Data loading test complete in\", time.time() - start, \"seconds\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TDt5J3p7yfXv",
        "outputId": "2819504a-0090-403e-c63f-32ab98226f01"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch 1: torch.Size([32, 3, 224, 224]), torch.Size([32])\n",
            "Batch 2: torch.Size([32, 3, 224, 224]), torch.Size([32])\n",
            "Batch 3: torch.Size([32, 3, 224, 224]), torch.Size([32])\n",
            "Data loading test complete in 0.5335745811462402 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=2)"
      ],
      "metadata": {
        "id": "JeejjoKGyv7Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Using device:\", device)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bEEYRerty2JI",
        "outputId": "670c890e-2729-4184-dfcd-f5d48644b252"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(1, 2):  # just run one for now\n",
        "    model.train()\n",
        "    start_time = time.time()\n",
        "    total_loss = 0\n",
        "    for batch_idx, (images, labels) in enumerate(train_loader):\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item()\n",
        "\n",
        "        if batch_idx % 10 == 0:\n",
        "            print(f\"Epoch {epoch}, Batch {batch_idx}, Loss: {loss.item():.4f}\")\n",
        "    print(f\"Epoch {epoch} done in {time.time() - start_time:.2f}s, Total Loss: {total_loss:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "Be0mo_U4jhd8",
        "outputId": "6f452fd2-6043-4fdd-f36a-93a53ec59c76"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Batch 0, Loss: 0.1355\n",
            "Epoch 1, Batch 10, Loss: 0.3841\n",
            "Epoch 1, Batch 20, Loss: 0.2513\n",
            "Epoch 1, Batch 30, Loss: 0.3207\n",
            "Epoch 1, Batch 40, Loss: 0.2539\n",
            "Epoch 1, Batch 50, Loss: 0.1993\n",
            "Epoch 1, Batch 60, Loss: 0.3361\n",
            "Epoch 1, Batch 70, Loss: 0.4181\n",
            "Epoch 1, Batch 80, Loss: 0.2478\n",
            "Epoch 1, Batch 90, Loss: 0.2385\n",
            "Epoch 1, Batch 100, Loss: 0.3400\n",
            "Epoch 1, Batch 110, Loss: 0.2212\n",
            "Epoch 1, Batch 120, Loss: 0.1996\n",
            "Epoch 1, Batch 130, Loss: 0.4116\n",
            "Epoch 1, Batch 140, Loss: 0.3441\n",
            "Epoch 1, Batch 150, Loss: 0.3699\n",
            "Epoch 1, Batch 160, Loss: 0.3152\n",
            "Epoch 1, Batch 170, Loss: 0.2265\n",
            "Epoch 1, Batch 180, Loss: 0.3296\n",
            "Epoch 1, Batch 190, Loss: 0.2823\n",
            "Epoch 1, Batch 200, Loss: 0.2071\n",
            "Epoch 1, Batch 210, Loss: 0.3216\n",
            "Epoch 1, Batch 220, Loss: 0.2708\n",
            "Epoch 1, Batch 230, Loss: 0.2753\n",
            "Epoch 1, Batch 240, Loss: 0.4518\n",
            "Epoch 1, Batch 250, Loss: 0.3099\n",
            "Epoch 1, Batch 260, Loss: 0.1456\n",
            "Epoch 1, Batch 270, Loss: 0.2477\n",
            "Epoch 1, Batch 280, Loss: 0.2442\n",
            "Epoch 1, Batch 290, Loss: 0.2983\n",
            "Epoch 1, Batch 300, Loss: 0.2160\n",
            "Epoch 1, Batch 310, Loss: 0.2363\n",
            "Epoch 1, Batch 320, Loss: 0.1940\n",
            "Epoch 1, Batch 330, Loss: 0.6103\n",
            "Epoch 1, Batch 340, Loss: 0.1900\n",
            "Epoch 1, Batch 350, Loss: 0.3374\n",
            "Epoch 1, Batch 360, Loss: 0.2382\n",
            "Epoch 1, Batch 370, Loss: 0.2416\n",
            "Epoch 1, Batch 380, Loss: 0.2259\n",
            "Epoch 1, Batch 390, Loss: 0.2945\n",
            "Epoch 1, Batch 400, Loss: 0.3099\n",
            "Epoch 1, Batch 410, Loss: 0.3390\n",
            "Epoch 1, Batch 420, Loss: 0.3321\n",
            "Epoch 1, Batch 430, Loss: 0.3715\n",
            "Epoch 1, Batch 440, Loss: 0.1915\n",
            "Epoch 1, Batch 450, Loss: 0.3891\n",
            "Epoch 1, Batch 460, Loss: 0.3502\n",
            "Epoch 1, Batch 470, Loss: 0.3160\n",
            "Epoch 1, Batch 480, Loss: 0.3437\n",
            "Epoch 1, Batch 490, Loss: 0.2200\n",
            "Epoch 1, Batch 500, Loss: 0.2446\n",
            "Epoch 1, Batch 510, Loss: 0.1422\n",
            "Epoch 1, Batch 520, Loss: 0.3232\n",
            "Epoch 1, Batch 530, Loss: 0.2272\n",
            "Epoch 1, Batch 540, Loss: 0.1692\n",
            "Epoch 1, Batch 550, Loss: 0.3962\n",
            "Epoch 1, Batch 560, Loss: 0.2661\n",
            "Epoch 1, Batch 570, Loss: 0.2029\n",
            "Epoch 1, Batch 580, Loss: 0.3136\n",
            "Epoch 1, Batch 590, Loss: 0.2845\n",
            "Epoch 1, Batch 600, Loss: 0.2093\n",
            "Epoch 1, Batch 610, Loss: 0.3404\n",
            "Epoch 1, Batch 620, Loss: 0.2076\n",
            "Epoch 1, Batch 630, Loss: 0.2903\n",
            "Epoch 1, Batch 640, Loss: 0.1955\n",
            "Epoch 1, Batch 650, Loss: 0.3275\n",
            "Epoch 1, Batch 660, Loss: 0.3152\n",
            "Epoch 1, Batch 670, Loss: 0.1850\n",
            "Epoch 1, Batch 680, Loss: 0.3814\n",
            "Epoch 1, Batch 690, Loss: 0.2431\n",
            "Epoch 1, Batch 700, Loss: 0.2904\n",
            "Epoch 1, Batch 710, Loss: 0.2723\n",
            "Epoch 1, Batch 720, Loss: 0.5236\n",
            "Epoch 1, Batch 730, Loss: 0.3396\n",
            "Epoch 1, Batch 740, Loss: 0.1793\n",
            "Epoch 1, Batch 750, Loss: 0.1966\n",
            "Epoch 1, Batch 760, Loss: 0.4444\n",
            "Epoch 1, Batch 770, Loss: 0.1959\n",
            "Epoch 1, Batch 780, Loss: 0.2787\n",
            "Epoch 1, Batch 790, Loss: 0.2273\n",
            "Epoch 1, Batch 800, Loss: 0.5679\n",
            "Epoch 1, Batch 810, Loss: 0.2940\n",
            "Epoch 1, Batch 820, Loss: 0.2853\n",
            "Epoch 1, Batch 830, Loss: 0.3567\n",
            "Epoch 1, Batch 840, Loss: 0.4060\n",
            "Epoch 1, Batch 850, Loss: 0.3636\n",
            "Epoch 1, Batch 860, Loss: 0.3876\n",
            "Epoch 1, Batch 870, Loss: 0.2839\n",
            "Epoch 1, Batch 880, Loss: 0.4269\n",
            "Epoch 1, Batch 890, Loss: 0.4349\n",
            "Epoch 1, Batch 900, Loss: 0.2582\n",
            "Epoch 1, Batch 910, Loss: 0.4792\n",
            "Epoch 1, Batch 920, Loss: 0.3019\n",
            "Epoch 1, Batch 930, Loss: 0.1782\n",
            "Epoch 1, Batch 940, Loss: 0.3945\n",
            "Epoch 1, Batch 950, Loss: 0.3435\n",
            "Epoch 1, Batch 960, Loss: 0.3630\n",
            "Epoch 1, Batch 970, Loss: 0.3043\n",
            "Epoch 1, Batch 980, Loss: 0.4172\n",
            "Epoch 1, Batch 990, Loss: 0.2759\n",
            "Epoch 1, Batch 1000, Loss: 0.2672\n",
            "Epoch 1, Batch 1010, Loss: 0.3191\n",
            "Epoch 1, Batch 1020, Loss: 0.3523\n",
            "Epoch 1, Batch 1030, Loss: 0.4330\n",
            "Epoch 1, Batch 1040, Loss: 0.2544\n",
            "Epoch 1, Batch 1050, Loss: 0.5810\n",
            "Epoch 1, Batch 1060, Loss: 0.2474\n",
            "Epoch 1, Batch 1070, Loss: 0.2021\n",
            "Epoch 1, Batch 1080, Loss: 0.2172\n",
            "Epoch 1, Batch 1090, Loss: 0.3396\n",
            "Epoch 1, Batch 1100, Loss: 0.3979\n",
            "Epoch 1, Batch 1110, Loss: 0.3398\n",
            "Epoch 1, Batch 1120, Loss: 0.2220\n",
            "Epoch 1, Batch 1130, Loss: 0.2705\n",
            "Epoch 1, Batch 1140, Loss: 0.3106\n",
            "Epoch 1, Batch 1150, Loss: 0.1843\n",
            "Epoch 1, Batch 1160, Loss: 0.2312\n",
            "Epoch 1, Batch 1170, Loss: 0.1801\n",
            "Epoch 1, Batch 1180, Loss: 0.2030\n",
            "Epoch 1, Batch 1190, Loss: 0.1222\n",
            "Epoch 1, Batch 1200, Loss: 0.4822\n",
            "Epoch 1, Batch 1210, Loss: 0.4876\n",
            "Epoch 1, Batch 1220, Loss: 0.1937\n",
            "Epoch 1, Batch 1230, Loss: 0.2313\n",
            "Epoch 1, Batch 1240, Loss: 0.4053\n",
            "Epoch 1, Batch 1250, Loss: 0.3948\n",
            "Epoch 1, Batch 1260, Loss: 0.3446\n",
            "Epoch 1, Batch 1270, Loss: 0.4161\n",
            "Epoch 1, Batch 1280, Loss: 0.2318\n",
            "Epoch 1, Batch 1290, Loss: 0.1509\n",
            "Epoch 1, Batch 1300, Loss: 0.5191\n",
            "Epoch 1, Batch 1310, Loss: 0.1952\n",
            "Epoch 1, Batch 1320, Loss: 0.1281\n",
            "Epoch 1, Batch 1330, Loss: 0.2885\n",
            "Epoch 1, Batch 1340, Loss: 0.2450\n",
            "Epoch 1, Batch 1350, Loss: 0.3471\n",
            "Epoch 1, Batch 1360, Loss: 0.3224\n",
            "Epoch 1, Batch 1370, Loss: 0.3110\n",
            "Epoch 1, Batch 1380, Loss: 0.1961\n",
            "Epoch 1, Batch 1390, Loss: 0.6388\n",
            "Epoch 1, Batch 1400, Loss: 0.3894\n",
            "Epoch 1, Batch 1410, Loss: 0.6004\n",
            "Epoch 1, Batch 1420, Loss: 0.1963\n",
            "Epoch 1, Batch 1430, Loss: 0.5012\n",
            "Epoch 1, Batch 1440, Loss: 0.2291\n",
            "Epoch 1, Batch 1450, Loss: 0.2824\n",
            "Epoch 1, Batch 1460, Loss: 0.1446\n",
            "Epoch 1, Batch 1470, Loss: 0.2762\n",
            "Epoch 1, Batch 1480, Loss: 0.2754\n",
            "Epoch 1, Batch 1490, Loss: 0.2231\n",
            "Epoch 1, Batch 1500, Loss: 0.2688\n",
            "Epoch 1, Batch 1510, Loss: 0.1411\n",
            "Epoch 1, Batch 1520, Loss: 0.2147\n",
            "Epoch 1, Batch 1530, Loss: 0.1932\n",
            "Epoch 1, Batch 1540, Loss: 0.2179\n",
            "Epoch 1, Batch 1550, Loss: 0.2511\n",
            "Epoch 1, Batch 1560, Loss: 0.2215\n",
            "Epoch 1, Batch 1570, Loss: 0.2246\n",
            "Epoch 1, Batch 1580, Loss: 0.1393\n",
            "Epoch 1, Batch 1590, Loss: 0.1944\n",
            "Epoch 1, Batch 1600, Loss: 0.3216\n",
            "Epoch 1, Batch 1610, Loss: 0.2653\n",
            "Epoch 1, Batch 1620, Loss: 0.2926\n",
            "Epoch 1, Batch 1630, Loss: 0.2795\n",
            "Epoch 1, Batch 1640, Loss: 0.3645\n",
            "Epoch 1, Batch 1650, Loss: 0.5619\n",
            "Epoch 1, Batch 1660, Loss: 0.2455\n",
            "Epoch 1, Batch 1670, Loss: 0.4412\n",
            "Epoch 1, Batch 1680, Loss: 0.3396\n",
            "Epoch 1, Batch 1690, Loss: 0.3213\n",
            "Epoch 1, Batch 1700, Loss: 0.2222\n",
            "Epoch 1, Batch 1710, Loss: 0.2341\n",
            "Epoch 1, Batch 1720, Loss: 0.1961\n",
            "Epoch 1, Batch 1730, Loss: 0.2833\n",
            "Epoch 1, Batch 1740, Loss: 0.3115\n",
            "Epoch 1, Batch 1750, Loss: 0.2971\n",
            "Epoch 1, Batch 1760, Loss: 0.1598\n",
            "Epoch 1, Batch 1770, Loss: 0.5308\n",
            "Epoch 1, Batch 1780, Loss: 0.2518\n",
            "Epoch 1, Batch 1790, Loss: 0.2491\n",
            "Epoch 1, Batch 1800, Loss: 0.1531\n",
            "Epoch 1, Batch 1810, Loss: 0.1332\n",
            "Epoch 1, Batch 1820, Loss: 0.3141\n",
            "Epoch 1, Batch 1830, Loss: 0.2885\n",
            "Epoch 1, Batch 1840, Loss: 0.4389\n",
            "Epoch 1, Batch 1850, Loss: 0.1430\n",
            "Epoch 1, Batch 1860, Loss: 0.1530\n",
            "Epoch 1, Batch 1870, Loss: 0.3811\n",
            "Epoch 1, Batch 1880, Loss: 0.4320\n",
            "Epoch 1, Batch 1890, Loss: 0.2740\n",
            "Epoch 1, Batch 1900, Loss: 0.1155\n",
            "Epoch 1, Batch 1910, Loss: 0.2662\n",
            "Epoch 1, Batch 1920, Loss: 0.1907\n",
            "Epoch 1, Batch 1930, Loss: 0.3059\n",
            "Epoch 1, Batch 1940, Loss: 0.1885\n",
            "Epoch 1, Batch 1950, Loss: 0.3050\n",
            "Epoch 1, Batch 1960, Loss: 0.1566\n",
            "Epoch 1, Batch 1970, Loss: 0.2152\n",
            "Epoch 1, Batch 1980, Loss: 0.2108\n",
            "Epoch 1, Batch 1990, Loss: 0.2967\n",
            "Epoch 1, Batch 2000, Loss: 0.2059\n",
            "Epoch 1, Batch 2010, Loss: 0.2604\n",
            "Epoch 1, Batch 2020, Loss: 0.1443\n",
            "Epoch 1, Batch 2030, Loss: 0.1246\n",
            "Epoch 1, Batch 2040, Loss: 0.3457\n",
            "Epoch 1, Batch 2050, Loss: 0.2782\n",
            "Epoch 1, Batch 2060, Loss: 0.1890\n",
            "Epoch 1, Batch 2070, Loss: 0.2420\n",
            "Epoch 1, Batch 2080, Loss: 0.1703\n",
            "Epoch 1, Batch 2090, Loss: 0.1647\n",
            "Epoch 1, Batch 2100, Loss: 0.2732\n",
            "Epoch 1, Batch 2110, Loss: 0.1296\n",
            "Epoch 1, Batch 2120, Loss: 0.1308\n",
            "Epoch 1, Batch 2130, Loss: 0.5200\n",
            "Epoch 1, Batch 2140, Loss: 0.3962\n",
            "Epoch 1, Batch 2150, Loss: 0.2237\n",
            "Epoch 1, Batch 2160, Loss: 0.4011\n",
            "Epoch 1, Batch 2170, Loss: 0.2844\n",
            "Epoch 1, Batch 2180, Loss: 0.2802\n",
            "Epoch 1, Batch 2190, Loss: 0.2627\n",
            "Epoch 1, Batch 2200, Loss: 0.2905\n",
            "Epoch 1, Batch 2210, Loss: 0.2029\n",
            "Epoch 1, Batch 2220, Loss: 0.3034\n",
            "Epoch 1, Batch 2230, Loss: 0.1444\n",
            "Epoch 1, Batch 2240, Loss: 0.5835\n",
            "Epoch 1, Batch 2250, Loss: 0.3266\n",
            "Epoch 1, Batch 2260, Loss: 0.3081\n",
            "Epoch 1, Batch 2270, Loss: 0.3933\n",
            "Epoch 1, Batch 2280, Loss: 0.1299\n",
            "Epoch 1, Batch 2290, Loss: 0.2652\n",
            "Epoch 1, Batch 2300, Loss: 0.2873\n",
            "Epoch 1, Batch 2310, Loss: 0.2088\n",
            "Epoch 1, Batch 2320, Loss: 0.4577\n",
            "Epoch 1, Batch 2330, Loss: 0.2757\n",
            "Epoch 1, Batch 2340, Loss: 0.2073\n",
            "Epoch 1, Batch 2350, Loss: 0.2963\n",
            "Epoch 1, Batch 2360, Loss: 0.2639\n",
            "Epoch 1, Batch 2370, Loss: 0.0732\n",
            "Epoch 1, Batch 2380, Loss: 0.2544\n",
            "Epoch 1, Batch 2390, Loss: 0.1961\n",
            "Epoch 1, Batch 2400, Loss: 0.3192\n",
            "Epoch 1, Batch 2410, Loss: 0.1693\n",
            "Epoch 1, Batch 2420, Loss: 0.1463\n",
            "Epoch 1, Batch 2430, Loss: 0.3045\n",
            "Epoch 1, Batch 2440, Loss: 0.2945\n",
            "Epoch 1, Batch 2450, Loss: 0.2737\n",
            "Epoch 1, Batch 2460, Loss: 0.1757\n",
            "Epoch 1, Batch 2470, Loss: 0.1271\n",
            "Epoch 1, Batch 2480, Loss: 0.1303\n",
            "Epoch 1, Batch 2490, Loss: 0.2480\n",
            "Epoch 1, Batch 2500, Loss: 0.1103\n",
            "Epoch 1, Batch 2510, Loss: 0.1638\n",
            "Epoch 1, Batch 2520, Loss: 0.1287\n",
            "Epoch 1, Batch 2530, Loss: 0.1560\n",
            "Epoch 1, Batch 2540, Loss: 0.3914\n",
            "Epoch 1, Batch 2550, Loss: 0.2669\n",
            "Epoch 1, Batch 2560, Loss: 0.1312\n",
            "Epoch 1, Batch 2570, Loss: 0.1664\n",
            "Epoch 1, Batch 2580, Loss: 0.2042\n",
            "Epoch 1, Batch 2590, Loss: 0.3983\n",
            "Epoch 1, Batch 2600, Loss: 0.1851\n",
            "Epoch 1, Batch 2610, Loss: 0.1923\n",
            "Epoch 1, Batch 2620, Loss: 0.2159\n",
            "Epoch 1, Batch 2630, Loss: 0.1017\n",
            "Epoch 1, Batch 2640, Loss: 0.2766\n",
            "Epoch 1, Batch 2650, Loss: 0.1881\n",
            "Epoch 1, Batch 2660, Loss: 0.1835\n",
            "Epoch 1, Batch 2670, Loss: 0.2605\n",
            "Epoch 1, Batch 2680, Loss: 0.1853\n",
            "Epoch 1, Batch 2690, Loss: 0.1476\n",
            "Epoch 1, Batch 2700, Loss: 0.4570\n",
            "Epoch 1, Batch 2710, Loss: 0.1627\n",
            "Epoch 1, Batch 2720, Loss: 0.2464\n",
            "Epoch 1, Batch 2730, Loss: 0.1515\n",
            "Epoch 1, Batch 2740, Loss: 0.2565\n",
            "Epoch 1, Batch 2750, Loss: 0.1762\n",
            "Epoch 1, Batch 2760, Loss: 0.1642\n",
            "Epoch 1, Batch 2770, Loss: 0.1450\n",
            "Epoch 1, Batch 2780, Loss: 0.1025\n",
            "Epoch 1, Batch 2790, Loss: 0.2578\n",
            "Epoch 1, Batch 2800, Loss: 0.2739\n",
            "Epoch 1, Batch 2810, Loss: 0.1605\n",
            "Epoch 1, Batch 2820, Loss: 0.2920\n",
            "Epoch 1, Batch 2830, Loss: 0.2751\n",
            "Epoch 1, Batch 2840, Loss: 0.4466\n",
            "Epoch 1, Batch 2850, Loss: 0.3331\n",
            "Epoch 1, Batch 2860, Loss: 0.2019\n",
            "Epoch 1, Batch 2870, Loss: 0.2797\n",
            "Epoch 1, Batch 2880, Loss: 0.2229\n",
            "Epoch 1, Batch 2890, Loss: 0.1878\n",
            "Epoch 1, Batch 2900, Loss: 0.1481\n",
            "Epoch 1, Batch 2910, Loss: 0.2662\n",
            "Epoch 1, Batch 2920, Loss: 0.1264\n",
            "Epoch 1, Batch 2930, Loss: 0.5685\n",
            "Epoch 1, Batch 2940, Loss: 0.2693\n",
            "Epoch 1, Batch 2950, Loss: 0.2177\n",
            "Epoch 1, Batch 2960, Loss: 0.2716\n",
            "Epoch 1, Batch 2970, Loss: 0.2251\n",
            "Epoch 1, Batch 2980, Loss: 0.2418\n",
            "Epoch 1, Batch 2990, Loss: 0.2279\n",
            "Epoch 1, Batch 3000, Loss: 0.2271\n",
            "Epoch 1, Batch 3010, Loss: 0.3681\n",
            "Epoch 1, Batch 3020, Loss: 0.2278\n",
            "Epoch 1, Batch 3030, Loss: 0.1857\n",
            "Epoch 1, Batch 3040, Loss: 0.3763\n",
            "Epoch 1, Batch 3050, Loss: 0.1363\n",
            "Epoch 1, Batch 3060, Loss: 0.2602\n",
            "Epoch 1, Batch 3070, Loss: 0.1655\n",
            "Epoch 1, Batch 3080, Loss: 0.1910\n",
            "Epoch 1, Batch 3090, Loss: 0.4128\n",
            "Epoch 1, Batch 3100, Loss: 0.2422\n",
            "Epoch 1, Batch 3110, Loss: 0.2833\n",
            "Epoch 1, Batch 3120, Loss: 0.3158\n",
            "Epoch 1, Batch 3130, Loss: 0.2230\n",
            "Epoch 1, Batch 3140, Loss: 0.1513\n",
            "Epoch 1, Batch 3150, Loss: 0.1301\n",
            "Epoch 1, Batch 3160, Loss: 0.3407\n",
            "Epoch 1, Batch 3170, Loss: 0.2946\n",
            "Epoch 1, Batch 3180, Loss: 0.3002\n",
            "Epoch 1, Batch 3190, Loss: 0.3967\n",
            "Epoch 1, Batch 3200, Loss: 0.1311\n",
            "Epoch 1, Batch 3210, Loss: 0.4061\n",
            "Epoch 1, Batch 3220, Loss: 0.1542\n",
            "Epoch 1, Batch 3230, Loss: 0.1175\n",
            "Epoch 1, Batch 3240, Loss: 0.2877\n",
            "Epoch 1, Batch 3250, Loss: 0.2649\n",
            "Epoch 1, Batch 3260, Loss: 0.2663\n",
            "Epoch 1, Batch 3270, Loss: 0.4136\n",
            "Epoch 1, Batch 3280, Loss: 0.0568\n",
            "Epoch 1, Batch 3290, Loss: 0.2888\n",
            "Epoch 1, Batch 3300, Loss: 0.2407\n",
            "Epoch 1, Batch 3310, Loss: 0.4227\n",
            "Epoch 1, Batch 3320, Loss: 0.2430\n",
            "Epoch 1, Batch 3330, Loss: 0.2408\n",
            "Epoch 1, Batch 3340, Loss: 0.1272\n",
            "Epoch 1, Batch 3350, Loss: 0.2232\n",
            "Epoch 1, Batch 3360, Loss: 0.3076\n",
            "Epoch 1, Batch 3370, Loss: 0.1328\n",
            "Epoch 1, Batch 3380, Loss: 0.2548\n",
            "Epoch 1, Batch 3390, Loss: 0.1609\n",
            "Epoch 1, Batch 3400, Loss: 0.1772\n",
            "Epoch 1, Batch 3410, Loss: 0.4483\n",
            "Epoch 1, Batch 3420, Loss: 0.3170\n",
            "Epoch 1, Batch 3430, Loss: 0.1850\n",
            "Epoch 1, Batch 3440, Loss: 0.1785\n",
            "Epoch 1, Batch 3450, Loss: 0.2078\n",
            "Epoch 1, Batch 3460, Loss: 0.1551\n",
            "Epoch 1, Batch 3470, Loss: 0.5132\n",
            "Epoch 1, Batch 3480, Loss: 0.1522\n",
            "Epoch 1, Batch 3490, Loss: 0.2945\n",
            "Epoch 1, Batch 3500, Loss: 0.2310\n",
            "Epoch 1, Batch 3510, Loss: 0.4228\n",
            "Epoch 1, Batch 3520, Loss: 0.2261\n",
            "Epoch 1, Batch 3530, Loss: 0.2268\n",
            "Epoch 1, Batch 3540, Loss: 0.2277\n",
            "Epoch 1, Batch 3550, Loss: 0.2526\n",
            "Epoch 1, Batch 3560, Loss: 0.2201\n",
            "Epoch 1, Batch 3570, Loss: 0.1479\n",
            "Epoch 1, Batch 3580, Loss: 0.2551\n",
            "Epoch 1, Batch 3590, Loss: 0.1711\n",
            "Epoch 1, Batch 3600, Loss: 0.1447\n",
            "Epoch 1, Batch 3610, Loss: 0.2632\n",
            "Epoch 1, Batch 3620, Loss: 0.1951\n",
            "Epoch 1, Batch 3630, Loss: 0.2480\n",
            "Epoch 1, Batch 3640, Loss: 0.3432\n",
            "Epoch 1, Batch 3650, Loss: 0.2575\n",
            "Epoch 1, Batch 3660, Loss: 0.3499\n",
            "Epoch 1, Batch 3670, Loss: 0.2263\n",
            "Epoch 1, Batch 3680, Loss: 0.1361\n",
            "Epoch 1, Batch 3690, Loss: 0.2069\n",
            "Epoch 1, Batch 3700, Loss: 0.2754\n",
            "Epoch 1, Batch 3710, Loss: 0.1537\n",
            "Epoch 1, Batch 3720, Loss: 0.1515\n",
            "Epoch 1, Batch 3730, Loss: 0.3684\n",
            "Epoch 1, Batch 3740, Loss: 0.1896\n",
            "Epoch 1, Batch 3750, Loss: 0.1484\n",
            "Epoch 1, Batch 3760, Loss: 0.2896\n",
            "Epoch 1, Batch 3770, Loss: 0.1650\n",
            "Epoch 1, Batch 3780, Loss: 0.1764\n",
            "Epoch 1, Batch 3790, Loss: 0.2407\n",
            "Epoch 1, Batch 3800, Loss: 0.2372\n",
            "Epoch 1, Batch 3810, Loss: 0.1959\n",
            "Epoch 1, Batch 3820, Loss: 0.3669\n",
            "Epoch 1, Batch 3830, Loss: 0.2241\n",
            "Epoch 1, Batch 3840, Loss: 0.1857\n",
            "Epoch 1, Batch 3850, Loss: 0.1975\n",
            "Epoch 1, Batch 3860, Loss: 0.1715\n",
            "Epoch 1, Batch 3870, Loss: 0.2130\n",
            "Epoch 1, Batch 3880, Loss: 0.1681\n",
            "Epoch 1, Batch 3890, Loss: 0.2554\n",
            "Epoch 1, Batch 3900, Loss: 0.1651\n",
            "Epoch 1, Batch 3910, Loss: 0.2409\n",
            "Epoch 1, Batch 3920, Loss: 0.4006\n",
            "Epoch 1, Batch 3930, Loss: 0.1690\n",
            "Epoch 1, Batch 3940, Loss: 0.3266\n",
            "Epoch 1, Batch 3950, Loss: 0.2018\n",
            "Epoch 1, Batch 3960, Loss: 0.1717\n",
            "Epoch 1, Batch 3970, Loss: 0.1629\n",
            "Epoch 1, Batch 3980, Loss: 0.2037\n",
            "Epoch 1, Batch 3990, Loss: 0.1239\n",
            "Epoch 1, Batch 4000, Loss: 0.2168\n",
            "Epoch 1, Batch 4010, Loss: 0.2927\n",
            "Epoch 1, Batch 4020, Loss: 0.2405\n",
            "Epoch 1, Batch 4030, Loss: 0.1658\n",
            "Epoch 1, Batch 4040, Loss: 0.2923\n",
            "Epoch 1, Batch 4050, Loss: 0.2011\n",
            "Epoch 1, Batch 4060, Loss: 0.6751\n",
            "Epoch 1, Batch 4070, Loss: 0.2514\n",
            "Epoch 1, Batch 4080, Loss: 0.1360\n",
            "Epoch 1, Batch 4090, Loss: 0.0899\n",
            "Epoch 1, Batch 4100, Loss: 0.1387\n",
            "Epoch 1, Batch 4110, Loss: 0.2651\n",
            "Epoch 1, Batch 4120, Loss: 0.2748\n",
            "Epoch 1, Batch 4130, Loss: 0.2288\n",
            "Epoch 1, Batch 4140, Loss: 0.1670\n",
            "Epoch 1, Batch 4150, Loss: 0.2227\n",
            "Epoch 1, Batch 4160, Loss: 0.1640\n",
            "Epoch 1, Batch 4170, Loss: 0.1374\n",
            "Epoch 1, Batch 4180, Loss: 0.1027\n",
            "Epoch 1, Batch 4190, Loss: 0.2168\n",
            "Epoch 1, Batch 4200, Loss: 0.2466\n",
            "Epoch 1, Batch 4210, Loss: 0.2056\n",
            "Epoch 1, Batch 4220, Loss: 0.1615\n",
            "Epoch 1, Batch 4230, Loss: 0.2809\n",
            "Epoch 1, Batch 4240, Loss: 0.2769\n",
            "Epoch 1, Batch 4250, Loss: 0.2292\n",
            "Epoch 1, Batch 4260, Loss: 0.1006\n",
            "Epoch 1, Batch 4270, Loss: 0.1602\n",
            "Epoch 1, Batch 4280, Loss: 0.3125\n",
            "Epoch 1, Batch 4290, Loss: 0.0724\n",
            "Epoch 1, Batch 4300, Loss: 0.1723\n",
            "Epoch 1, Batch 4310, Loss: 0.1788\n",
            "Epoch 1, Batch 4320, Loss: 0.1838\n",
            "Epoch 1, Batch 4330, Loss: 0.2653\n",
            "Epoch 1, Batch 4340, Loss: 0.1480\n",
            "Epoch 1, Batch 4350, Loss: 0.2406\n",
            "Epoch 1, Batch 4360, Loss: 0.3823\n",
            "Epoch 1, Batch 4370, Loss: 0.2555\n",
            "Epoch 1 done in 4673.45s, Total Loss: 1159.4621\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n"
      ],
      "metadata": {
        "id": "8vTm2GHbzEaC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "ZWyztXxWLJRp",
        "outputId": "04c3170f-12b7-4c9a-c091-2f122c86d707"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "VisionTransformer(\n",
              "  (patch_embed): PatchEmbed(\n",
              "    (proj): Conv2d(3, 768, kernel_size=(16, 16), stride=(16, 16))\n",
              "    (norm): Identity()\n",
              "  )\n",
              "  (pos_drop): Dropout(p=0.0, inplace=False)\n",
              "  (patch_drop): Identity()\n",
              "  (norm_pre): Identity()\n",
              "  (blocks): Sequential(\n",
              "    (0): Block(\n",
              "      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "      (attn): Attention(\n",
              "        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
              "        (q_norm): Identity()\n",
              "        (k_norm): Identity()\n",
              "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "        (norm): Identity()\n",
              "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (ls1): Identity()\n",
              "      (drop_path1): Identity()\n",
              "      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "      (mlp): Mlp(\n",
              "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        (act): GELU(approximate='none')\n",
              "        (drop1): Dropout(p=0.0, inplace=False)\n",
              "        (norm): Identity()\n",
              "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        (drop2): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (ls2): Identity()\n",
              "      (drop_path2): Identity()\n",
              "    )\n",
              "    (1): Block(\n",
              "      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "      (attn): Attention(\n",
              "        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
              "        (q_norm): Identity()\n",
              "        (k_norm): Identity()\n",
              "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "        (norm): Identity()\n",
              "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (ls1): Identity()\n",
              "      (drop_path1): Identity()\n",
              "      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "      (mlp): Mlp(\n",
              "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        (act): GELU(approximate='none')\n",
              "        (drop1): Dropout(p=0.0, inplace=False)\n",
              "        (norm): Identity()\n",
              "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        (drop2): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (ls2): Identity()\n",
              "      (drop_path2): Identity()\n",
              "    )\n",
              "    (2): Block(\n",
              "      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "      (attn): Attention(\n",
              "        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
              "        (q_norm): Identity()\n",
              "        (k_norm): Identity()\n",
              "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "        (norm): Identity()\n",
              "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (ls1): Identity()\n",
              "      (drop_path1): Identity()\n",
              "      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "      (mlp): Mlp(\n",
              "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        (act): GELU(approximate='none')\n",
              "        (drop1): Dropout(p=0.0, inplace=False)\n",
              "        (norm): Identity()\n",
              "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        (drop2): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (ls2): Identity()\n",
              "      (drop_path2): Identity()\n",
              "    )\n",
              "    (3): Block(\n",
              "      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "      (attn): Attention(\n",
              "        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
              "        (q_norm): Identity()\n",
              "        (k_norm): Identity()\n",
              "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "        (norm): Identity()\n",
              "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (ls1): Identity()\n",
              "      (drop_path1): Identity()\n",
              "      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "      (mlp): Mlp(\n",
              "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        (act): GELU(approximate='none')\n",
              "        (drop1): Dropout(p=0.0, inplace=False)\n",
              "        (norm): Identity()\n",
              "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        (drop2): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (ls2): Identity()\n",
              "      (drop_path2): Identity()\n",
              "    )\n",
              "    (4): Block(\n",
              "      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "      (attn): Attention(\n",
              "        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
              "        (q_norm): Identity()\n",
              "        (k_norm): Identity()\n",
              "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "        (norm): Identity()\n",
              "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (ls1): Identity()\n",
              "      (drop_path1): Identity()\n",
              "      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "      (mlp): Mlp(\n",
              "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        (act): GELU(approximate='none')\n",
              "        (drop1): Dropout(p=0.0, inplace=False)\n",
              "        (norm): Identity()\n",
              "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        (drop2): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (ls2): Identity()\n",
              "      (drop_path2): Identity()\n",
              "    )\n",
              "    (5): Block(\n",
              "      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "      (attn): Attention(\n",
              "        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
              "        (q_norm): Identity()\n",
              "        (k_norm): Identity()\n",
              "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "        (norm): Identity()\n",
              "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (ls1): Identity()\n",
              "      (drop_path1): Identity()\n",
              "      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "      (mlp): Mlp(\n",
              "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        (act): GELU(approximate='none')\n",
              "        (drop1): Dropout(p=0.0, inplace=False)\n",
              "        (norm): Identity()\n",
              "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        (drop2): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (ls2): Identity()\n",
              "      (drop_path2): Identity()\n",
              "    )\n",
              "    (6): Block(\n",
              "      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "      (attn): Attention(\n",
              "        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
              "        (q_norm): Identity()\n",
              "        (k_norm): Identity()\n",
              "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "        (norm): Identity()\n",
              "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (ls1): Identity()\n",
              "      (drop_path1): Identity()\n",
              "      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "      (mlp): Mlp(\n",
              "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        (act): GELU(approximate='none')\n",
              "        (drop1): Dropout(p=0.0, inplace=False)\n",
              "        (norm): Identity()\n",
              "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        (drop2): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (ls2): Identity()\n",
              "      (drop_path2): Identity()\n",
              "    )\n",
              "    (7): Block(\n",
              "      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "      (attn): Attention(\n",
              "        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
              "        (q_norm): Identity()\n",
              "        (k_norm): Identity()\n",
              "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "        (norm): Identity()\n",
              "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (ls1): Identity()\n",
              "      (drop_path1): Identity()\n",
              "      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "      (mlp): Mlp(\n",
              "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        (act): GELU(approximate='none')\n",
              "        (drop1): Dropout(p=0.0, inplace=False)\n",
              "        (norm): Identity()\n",
              "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        (drop2): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (ls2): Identity()\n",
              "      (drop_path2): Identity()\n",
              "    )\n",
              "    (8): Block(\n",
              "      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "      (attn): Attention(\n",
              "        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
              "        (q_norm): Identity()\n",
              "        (k_norm): Identity()\n",
              "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "        (norm): Identity()\n",
              "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (ls1): Identity()\n",
              "      (drop_path1): Identity()\n",
              "      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "      (mlp): Mlp(\n",
              "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        (act): GELU(approximate='none')\n",
              "        (drop1): Dropout(p=0.0, inplace=False)\n",
              "        (norm): Identity()\n",
              "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        (drop2): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (ls2): Identity()\n",
              "      (drop_path2): Identity()\n",
              "    )\n",
              "    (9): Block(\n",
              "      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "      (attn): Attention(\n",
              "        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
              "        (q_norm): Identity()\n",
              "        (k_norm): Identity()\n",
              "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "        (norm): Identity()\n",
              "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (ls1): Identity()\n",
              "      (drop_path1): Identity()\n",
              "      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "      (mlp): Mlp(\n",
              "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        (act): GELU(approximate='none')\n",
              "        (drop1): Dropout(p=0.0, inplace=False)\n",
              "        (norm): Identity()\n",
              "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        (drop2): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (ls2): Identity()\n",
              "      (drop_path2): Identity()\n",
              "    )\n",
              "    (10): Block(\n",
              "      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "      (attn): Attention(\n",
              "        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
              "        (q_norm): Identity()\n",
              "        (k_norm): Identity()\n",
              "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "        (norm): Identity()\n",
              "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (ls1): Identity()\n",
              "      (drop_path1): Identity()\n",
              "      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "      (mlp): Mlp(\n",
              "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        (act): GELU(approximate='none')\n",
              "        (drop1): Dropout(p=0.0, inplace=False)\n",
              "        (norm): Identity()\n",
              "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        (drop2): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (ls2): Identity()\n",
              "      (drop_path2): Identity()\n",
              "    )\n",
              "    (11): Block(\n",
              "      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "      (attn): Attention(\n",
              "        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
              "        (q_norm): Identity()\n",
              "        (k_norm): Identity()\n",
              "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "        (norm): Identity()\n",
              "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (ls1): Identity()\n",
              "      (drop_path1): Identity()\n",
              "      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "      (mlp): Mlp(\n",
              "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        (act): GELU(approximate='none')\n",
              "        (drop1): Dropout(p=0.0, inplace=False)\n",
              "        (norm): Identity()\n",
              "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        (drop2): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (ls2): Identity()\n",
              "      (drop_path2): Identity()\n",
              "    )\n",
              "  )\n",
              "  (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "  (fc_norm): Identity()\n",
              "  (head_drop): Dropout(p=0.0, inplace=False)\n",
              "  (head): Linear(in_features=768, out_features=2, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "all_preds = []\n",
        "all_labels = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for inputs, labels in val_loader:  # or test_loader\n",
        "        inputs = inputs.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        outputs = model(inputs)\n",
        "        _, preds = torch.max(outputs, 1)\n",
        "\n",
        "        all_preds.extend(preds.cpu().numpy())\n",
        "        all_labels.extend(labels.cpu().numpy())\n"
      ],
      "metadata": {
        "id": "wPBNv94zLKkJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cm = confusion_matrix(all_labels, all_preds)\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
        "disp.plot(cmap=plt.cm.Blues)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 449
        },
        "id": "Yu_t6STBLNLW",
        "outputId": "e98d6ff7-4e7f-4dc4-bb28-98663e2b8d66"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(cm)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o5-i7l3pLOuh",
        "outputId": "e9521b25-ff11-4496-9cea-1fb377649217"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[17925  1716]\n",
            " [ 3337 16450]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "l24hoZmuLRq8"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "authorship_tag": "ABX9TyOkSAUVJdKTTAruwTrB4Ti3",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "2ac6d8d7fc84440fb3e065636e809bd1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ea29a63974f74243ae044d5fae83f6ea",
              "IPY_MODEL_8dd51d8914c642108776d3a4d90b3193",
              "IPY_MODEL_40e3e375d3a54cf39fecca4c65ec0cb8"
            ],
            "layout": "IPY_MODEL_d6de4cf463aa46f5b02bce94dea6a97e"
          }
        },
        "ea29a63974f74243ae044d5fae83f6ea": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_41b21d0595024a5cbaffef83abd179e7",
            "placeholder": "​",
            "style": "IPY_MODEL_c0dfff3c06a04ad9a9251bc32057ac9f",
            "value": "model.safetensors: 100%"
          }
        },
        "8dd51d8914c642108776d3a4d90b3193": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4cc67ea2a56b46e9bc9a12d2aa0bb5ec",
            "max": 346284714,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_289a43eec8cb43929c4ee3610f2f8b81",
            "value": 346284714
          }
        },
        "40e3e375d3a54cf39fecca4c65ec0cb8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cb9c347670d84cb18f7087629918e67e",
            "placeholder": "​",
            "style": "IPY_MODEL_deed8aa958c148f9bbe33b789f3bda56",
            "value": " 346M/346M [00:01&lt;00:00, 236MB/s]"
          }
        },
        "d6de4cf463aa46f5b02bce94dea6a97e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "41b21d0595024a5cbaffef83abd179e7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c0dfff3c06a04ad9a9251bc32057ac9f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4cc67ea2a56b46e9bc9a12d2aa0bb5ec": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "289a43eec8cb43929c4ee3610f2f8b81": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "cb9c347670d84cb18f7087629918e67e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "deed8aa958c148f9bbe33b789f3bda56": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}